{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/berkekincioglu/Desktop/root/data-science/machine_learning/16) natural-language-process/gender-classifier.csv',encoding='latin1')\n",
    "df = pd.concat([df.gender,df.description],axis=1)\n",
    "df.dropna(axis=0,inplace=True)\n",
    "df.gender = [1 if i == 'female' else  0 for i in df.gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   gender                                        description\n0       0                              i sing my own rhythm.\n1       0  I'm the author of novels filled with family dr...\n2       0                louis whining and squealing and all\n3       0  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...\n4       1  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>i sing my own rhythm.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>I'm the author of novels filled with family dr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>louis whining and squealing and all</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/berkekincioglu/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /Users/berkekincioglu/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     /Users/berkekincioglu/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
    }
   ],
   "source": [
    "import re \n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_list = []\n",
    "for description in df.description:\n",
    "    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n",
    "    description = description.lower()   # buyuk harftan kucuk harfe cevirme\n",
    "    description = nltk.word_tokenize(description)\n",
    "    #description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n",
    "    lemma = nltk.WordNetLemmatizer()\n",
    "    description = [ lemma.lemmatize(word) for word in description]\n",
    "    description = \" \".join(description)\n",
    "    description_list.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cV = CountVectorizer(max_features=2000,stop_words='english')\n",
    "space_matrix = cV.fit_transform(description_list).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df.iloc[:,0].values\n",
    "x = space_matrix\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train,y_train)\n",
    "prediction = gnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "accuracy:  0.436979969183359\n"
    }
   ],
   "source": [
    "print('accuracy: ',gnb.score(prediction.reshape(-1,1),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.563020030816641"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "gnb.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbasecondadaaf1e94dae24b6f8d0e7b42e0b816cc",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}